<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Project | Towards Net Zero IoT System</title>

  <style>
    :root {
      --primary: #0077b6;
      --secondary: #0096c7;
      --bg: #f9f9fb;
      --text: #222;
      --shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
    }

    body {
      font-family: 'Poppins', sans-serif;
      background: var(--bg);
      color: var(--text);
      margin: 0;
      padding: 0;
      line-height: 1.6;
      scroll-behavior: smooth;
    }

    header {
      background: var(--primary);
      color: white;
      padding: 1rem 2rem;
      display: flex;
      justify-content: space-between;
      align-items: center;
      box-shadow: var(--shadow);
    }

    header a {
      color: white;
      text-decoration: none;
      font-weight: 500;
      background: rgba(255, 255, 255, 0.1);
      padding: 0.5rem 1rem;
      border-radius: 8px;
      transition: 0.3s;
    }

    header a:hover {
      background: rgba(255, 255, 255, 0.3);
    }

    main {
      max-width: 1000px;
      margin: 2rem auto;
      background: white;
      padding: 2rem;
      border-radius: 16px;
      box-shadow: var(--shadow);
      animation: fadeIn 1s ease-in-out;
    }

    @keyframes fadeIn {
      from { opacity: 0; transform: translateY(20px); }
      to { opacity: 1; transform: translateY(0); }
    }

    h1 {
      color: var(--primary);
      text-align: center;
      margin-bottom: 1rem;
    }

    section {
      margin-bottom: 2rem;
    }

    h2 {
      color: var(--secondary);
      border-left: 4px solid var(--secondary);
      padding-left: 10px;
      margin-bottom: 1rem;
    }

    ul {
      list-style: disc;
      padding-left: 2rem;
    }

    .gallery {
      display: grid;
      grid-template-columns: repeat(2, 1fr);
      row-gap: 2rem;    /* space between rows */
  column-gap: 1rem; /* space between columns */
    }

    .gallery img {
  width: 100%;
  height: 100%; /* fixed height for all images */
      border: 2px solid black;
  object-fit: contain; /* makes image cover the space without distortion */
  border-radius: 12px;
  transition: transform 0.3s ease;
  box-shadow: var(--shadow);
}
    .gallery figcaption {
  text-align: center;      /* center horizontally */
  font-size: 1rem;
  color: #333;
      font-weight: bold;
}

    .gallery img:hover {
      transform: scale(1.05);
    }

    footer {
      text-align: center;
      margin: 2rem 0;
      color: #555;
    }
  </style>
</head>
<body>

  <header>
    <h3>Smart Object Identifying Robot</h3>
    <a href="https://armaghanabbasi.github.io/armaghan_abbasi/">← Back to Home</a>
  </header>

  <main>
    <h1>Smart Object Identifying Robot</h1>

    <section id="description">
      <h2>Project Overview</h2>
      <p>Humans use artificial intelligence to make machines work and act like humans. AI has recently accomplished this by developing machines and robots that are used in various fields such as healthcare,
         robotics, marketing, business analytics, and many others.</p>
      <p>However, many artificial intelligence applications are not interpreted as AI because we typically think
         of AI as robots doing our daily tasks, but in reality, artificial intelligence has made its way into our
         daily lives. The field of teaching machines to imitate human actions is known as artificial intelligence.
         On the other side, machine learning is a subset of Artificial intelligence that focuses on teaching machines to make decisions through the use of data. On the other hand, deep learning is a subcategory of
         machine learning that solves complex problems using the concept of neural networks. To sum it up, machine learning, artificial intelligence, and deep learning are all related fields. Deep learning and machine
         learning provide methods and neural networks to solve data-driven problems.</p>
      <p>In our project, for detecting an object, we have used the artificial intelligence algorithm YOLO V3 (details in Chapter 3). For the intelligent navigation of our robot, we have used a technique called template
         matching. Template matching is an image processing approach. By combining these two tasks, our robot
         can carry out multiple tasks such as for military purposes and waste management by detecting garbage
         material and notifying the management about the garbage at a particular location.</p>
    </section>

    <section id="objectives">
      <h2>Objectives</h2>
      <ul>
        <li>The project’s motive is to build a robot that performs object detection and recognition in real-time video capturing</li>
        <li>The robot will be able to locate the objects and navigate on a defined path. It will act independently on the defined area on which we have trained our robot and show us a list of detected objects.</li>
        <li> Furthermore, the robot will be able to move in all possible directions. NVIDIA Jetson Nano controls the movements of the robot.</li>
        <div class="gallery">
        <figure>
        <img src="https://raw.githubusercontent.com/armaghanabbasi/Smart-Object-Identifying-Robot/refs/heads/main/Objectives.png" alt="Objectives" />
        <figcaption> <strong> Objectives </strong></figcaption>
        </figure>
        </div>
        
      </ul>
    </section>

    <section id="technology">
      <h2>Technologies Used</h2>
      <h3>Core Communication Technology</h3>
    <ul>
      <li><strong>LoRa (Long Range Radio Communication):</strong> Provides low-power, long-range data transmission.</li>
      <li>Operates on <strong>868/915 MHz ISM bands</strong> with Chirp Spread Spectrum (CSS) modulation.</li>
      <li>Enables reliable IoT communication over several kilometres.</li>
      <li>Used for connecting sensor nodes to the <strong>USRP B210 gateway</strong>.</li>
    </ul>


  
    <h3>Hardware Components</h3>
    <ul>
      <li><strong>USRP B210 (Software Defined Radio):</strong> Acts as LoRa receiver; supports 70 MHz–6 GHz range with full-duplex 2×2 MIMO.</li>
      <li><strong>LILYGO TTGO LoRa32 (ESP32 + SX1276):</strong> Sensor node with Wi-Fi, Bluetooth, OLED display, and battery circuit.</li>
      <li><strong>Sensors:</strong> 
        <ul>
          <li>DHT11 – Measures temperature (0–50 °C) & humidity (20–90 % RH).</li>
          <li>LDR – Detects ambient light using LM393 comparator.</li>
        </ul>
      </li>
    </ul>

  
    <h3>Software & Tools</h3>
    <ul>
      <li><strong>Arduino IDE:</strong> For programming ESP32 firmware in C/C++.</li>
      <li><strong>GNU Radio (gr-lora_sdr):</strong> For LoRa signal decoding and SDR processing.</li>
      <li><strong>Python:</strong> Handles data forwarding and cloud integration.</li>
      <li><strong>Cloud Platforms:</strong>
        <ul>
          <li><strong>ThingSpeak:</strong> Real-time data logging, trend analysis, MATLAB analytics.</li>
          <li><strong>Blynk:</strong> Mobile dashboard with live widgets and push notifications.</li>
        </ul>
      </li>
    </ul>
</section>


    <section id="gallery">
      <h2>Project Gallery</h2>
      <div class="gallery">
        <figure>
        <img src="https://raw.githubusercontent.com/armaghanabbasi/Towards-Net-Zero-Internet-of-Things-IoT-System/refs/heads/main/Sensor%20Node.png" alt="IoT setup image 1" />
        <figcaption>Sensor Node</figcaption>
        </figure>

         <figure>
          <img src="https://raw.githubusercontent.com/armaghanabbasi/Towards-Net-Zero-Internet-of-Things-IoT-System/refs/heads/main/USRP.png" alt="Sensors used" />
        <figcaption>USRP B210</figcaption>
        </figure>

        <figure>
        <img src="https://raw.githubusercontent.com/armaghanabbasi/Towards-Net-Zero-Internet-of-Things-IoT-System/refs/heads/main/GNU%20Radio%20Flow%20Graph%20for%20Packet%20Reception.png" alt="Dashboard" />
        <figcaption>GNU Radio Flow Graph for Packet Reception</figcaption>
        </figure>

          <figure>
          <img src="https://raw.githubusercontent.com/armaghanabbasi/Towards-Net-Zero-Internet-of-Things-IoT-System/refs/heads/main/ThingSpeak%20Output.png" alt="Sensors used" />
         <figcaption>ThingSpeak Output</figcaption>
        </figure>

          <figure>  
          <img src="https://raw.githubusercontent.com/armaghanabbasi/Towards-Net-Zero-Internet-of-Things-IoT-System/refs/heads/main/Blynk%20Output.png" alt="Sensors used" />
          <figcaption>Blynk Output</figcaption>
        </figure>
     
      </div>
    </section>

    <section id="links">
      <h2>Links</h2>
      <p>
        <a href="https://github.com/armaghanabbasi/Towards-Net-Zero-Internet-of-Things-IoT-System" target="_blank">View Source on GitHub</a>
      </p>
    </section>
  </main>



</body>
</html>
